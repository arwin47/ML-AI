{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba17444",
   "metadata": {},
   "source": [
    "### Tweets Sentiment Prediction using NLP and Classification algorithm\n",
    "\n",
    "The goal is to predict if a review has got negative or positive sentiment aiding faster decision by the reader or the business in classifying reviews and make decisions basis the sentiment. Finding the sentiment also aids in summarizing the outcome for perfoemance measurement which otherwise becomes highly manual process.\n",
    "\n",
    "\n",
    "#### Dataset:\n",
    "The dataset contains tweets and associated sentiments tagged.\n",
    "Source: https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98442e0",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff00067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(r\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf885b",
   "metadata": {},
   "source": [
    "#### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80543715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60849e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11118\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afad22",
   "metadata": {},
   "source": [
    "In this section, we will look at only positive and negative reviews to do a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c281b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['sentiment'] == \"positive\") | (data['sentiment'] == \"negative\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6bfb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    8582\n",
       "negative    7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae34497",
   "metadata": {},
   "source": [
    "Data has good number of both classes of reviews and they are balanced. We'll use only the 'text' and 'sentiment' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4316baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caee695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                          my boss is bullying me...  negative\n",
       "3                     what interview! leave me alone  negative\n",
       "4   Sons of ****, why couldn`t they put them on t...  negative\n",
       "6  2am feedings for the baby are fun when he is a...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d15cac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index() # to remove outdated indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1764c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd2aaa0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "1                          my boss is bullying me...  negative\n",
       "2                     what interview! leave me alone  negative\n",
       "3   Sons of ****, why couldn`t they put them on t...  negative\n",
       "4  2am feedings for the baby are fun when he is a...  positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e6887",
   "metadata": {},
   "source": [
    "Making the sentiment numerical (0,1) for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72aafc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].apply(lambda x: 0 if x == \"negative\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "792f319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0      Sooo SAD I will miss you here in San Diego!!!          0\n",
       "1                          my boss is bullying me...          0\n",
       "2                     what interview! leave me alone          0\n",
       "3   Sons of ****, why couldn`t they put them on t...          0\n",
       "4  2am feedings for the baby are fun when he is a...          1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1943335",
   "metadata": {},
   "source": [
    "### NLP - Cleaning the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760b8e1",
   "metadata": {},
   "source": [
    "Functionalities and explanations for each cleaning step will be added as a part of another detailed readout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fa6ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Libraries for cleaning text data\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords') # To identify stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer  # To stem the word to it's basic form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52bfe919",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(0, len(data)):\n",
    "  tweet = re.sub('[^a-zA-Z]', ' ', data['text'][i])  # Using only alphabets\n",
    "  tweet = tweet.lower()   \n",
    "  tweet = tweet.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')   # using English stopwords\n",
    "  all_stopwords.remove('not')\n",
    "  tweet = [ps.stem(word) for word in tweet if not word in set(all_stopwords)] # stemming all words that are not stop words\n",
    "  tweet = ' '.join(tweet)\n",
    "  word_list.append(tweet)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93ebca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boss bulli',\n",
       " 'interview leav alon',\n",
       " 'son put releas alreadi bought',\n",
       " 'feed babi fun smile coo']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a4e61",
   "metadata": {},
   "source": [
    "Model can be improved by better methods available as we see they are not done as expected. \n",
    "Let us use lemmatizing which is a better and advanced way of reducing words to it's basic form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd036a5f",
   "metadata": {},
   "source": [
    "Downloading required resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e95dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1027571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "# Create WordNetLemmatizer object\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "313aadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(0, len(data)):\n",
    "  tweet = re.sub('[^a-zA-Z]', ' ', data['text'][i])  # Using only alphabets\n",
    "  tweet = tweet.lower()   \n",
    "  tweet = tweet.split()\n",
    "  all_stopwords = stopwords.words('english')   # using English stopwords\n",
    "  all_stopwords.remove('not')\n",
    "  tweet = [wnl.lemmatize(word) for word in tweet if not word in set(all_stopwords)] # lemmatizing all words that are not stop words\n",
    "  tweet = ' '.join(tweet)\n",
    "  word_list.append(tweet)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c26729c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bos bullying',\n",
       " 'interview leave alone',\n",
       " 'son put release already bought',\n",
       " 'feeding baby fun smile coo']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90856622",
   "metadata": {},
   "source": [
    "Lemmatized list is much better but still not great. Will use this list to train the model and understand the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b69d81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(word_list).toarray()\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e39c73",
   "metadata": {},
   "source": [
    "Checking the size of the X vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aedb35b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16221"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f436815",
   "metadata": {},
   "source": [
    "### Splitting dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc8bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8de0a",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fe2f8",
   "metadata": {},
   "source": [
    "Using a Naive Bayes classifier for classifying the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dedd7b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32533555",
   "metadata": {},
   "source": [
    "### Testing with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d92236e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb309e0",
   "metadata": {},
   "source": [
    "### Measuring accuracy and making confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6feeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1295  237]\n",
      " [1010  731]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6190039718912312"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc6c7b",
   "metadata": {},
   "source": [
    "Now limiting the vector to 15000 words to see if performance on test data increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7dd97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features= 15000)\n",
    "X = vectorizer.fit_transform(word_list).toarray()\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9d55d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c4cbf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1285  247]\n",
      " [ 972  769]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6275588145432325"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccbabf",
   "metadata": {},
   "source": [
    "We are able to icreae the accuracy by removing the over fitting by reducing the number of elements in the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78cdb285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1186  346]\n",
      " [ 503 1238]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7406049495875344"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features= 12000)\n",
    "X = vectorizer.fit_transform(word_list).toarray()\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e0398",
   "metadata": {},
   "source": [
    "By going with 12000 words vector, the accuracy that we achieved is 74%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
